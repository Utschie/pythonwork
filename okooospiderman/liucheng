n = 0
i = '2018-09-03'
start = time.time()
os.popen('mongod --config /etc/mongod.conf')
client = MongoClient()
db = client.okooo
UAcontent = urllib.request.urlopen('file:///home/jsy/Dropbox/useragentswitcher.xml').read()
UAcontent = str(UAcontent)
UAname = re.findall('(useragent=")(.*?)(")',UAcontent)
UAlist = list()
for z in range(0,int(len(UAname))):
    UAlist.append(UAname[z][1])

UAlist = UAlist[0:586]#这样就得到了一个拥有586个UA的UA池
UAlist.append('Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/61.0.3163.100 Safari/537.36')#再加一个
logpath = 'okooolog.txt'
header = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/61.0.3163.100 Safari/537.36'}#设置UA假装是浏览器
header['User-Agent'] = random.choice(UAlist)
proxycontent = requests.get('http://api.xdaili.cn/xdaili-api//privateProxy/applyStaticProxy?spiderId=0a4b8956ad274e579822b533d27f79e1&returnType=1&count=1') #接入混拨代理
print('已获取IP')
proxylist = re.findall('(.*?)\\r\\n',proxycontent.text)
print('正在检查IP')
proxylist = checkip(proxylist)
for j in range(0,len(proxylist)):
    proxylist[j] = {"http":"http://" + proxylist[j],}

print(proxylist)
r = requests.Session()#开启会话
r.proxies = random.choice(proxylist)
main()
ceshi = r.get('http://www.okooo.com/soccer/match/?date=2017-01-01',headers = header,verify=False,allow_redirects=False,timeout = 31)#进入1月1日，看看有没有重定向，有的话需要重新登录
while ceshi.status_code != 200:
    print('登录失败，正在重新登录')
    time.sleep(10)
    proxycontent = requests.get('http://api.xdaili.cn/xdaili-api//privateProxy/applyStaticProxy?spiderId=0a4b8956ad274e579822b533d27f79e1&returnType=1&count=1')#接入混拨代理
    print('已获取IP')
    proxylist = re.findall('(.*?)\\r\\n',proxycontent.text)
    print('正在检查IP')
    proxylist = checkip(proxylist)
    for l in range(0,len(proxylist)):
        proxylist[l] = {"http":"http://"+ proxylist[l],}
    print(proxylist)
    header = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/61.0.3163.100 Safari/537.36'}#设置UA假装是浏览器
    header['User-Agent'] = random.choice(UAlist)
    r = requests.Session()#开启会话
    r.proxies = random.choice(proxylist)
    main()
    ceshi = r.get('http://www.okooo.com/soccer/match/?date=2017-01-01',headers = header,verify=False,allow_redirects=False,timeout = 31)


print('登录成功')
print('准备进入：' + i)
starttime = time.time()
header3 = header
header3['Referer'] = 'http://www.okooo.com/soccer/'#必须加上这个才能进入足球日历
header3['Upgrade-Insecure-Requests'] = '1'#这个也得加上
wangye = r.get('http://www.okooo.com/soccer/match/?date=' + i,headers = header3,verify=False,allow_redirects=False,timeout = 31)
content1 = wangye.content.decode('gb18030')#取出wangye的源代码
sucker1 = '/soccer/match/.*?/odds/'
bisaiurl = re.findall(sucker1,content1)#获得当天的比赛列表
print(str(bisaiurl))
william = r.get('http://www.okooo.com' + bisaiurl[0] + 'change/14/',headers = header3,timeout = 31)#打开威廉希尔
content2 = william.content.decode('gb18030')
sucker2 = bisaiurl[0] + 'change/.*?/'
companyurl = re.findall(sucker2,content2)#从威廉的源码中获取其他公司的链接
for j in range(0,len(companyurl)):
    companyurl[j] = 'http://www.okooo.com' + companyurl[j]


header4 = header
header4['Referer'] = 'http://www.okooo.com/soccer/'#必须加上这个才能进入足球日历
header4['Upgrade-Insecure-Requests'] = '1'#这个也得加上
firma = r.get(companyurl[0],headers = header4,verify=False,allow_redirects=True,timeout = 9.5)#进入单个公司赔率的网页
content3 = firma.content.decode('GB18030')#获得该网页的代码
#提取数据用beautifulsoup和re结合的方式比较靠谱
sucker3 = '<a class="bluetxt" href="/soccer/match/(.*?)/odds/change/(.*?)/">'
sucker4 = '> <b>(.*?)</b>'
sucker5 = '/schedule/">(.*?)</a>'
sucker6 = 'odds/">(.*?) vs (.*?)</a>'
cid = re.search(sucker3,content3).group(2)
urlnum = re.search(sucker3,content3).group(1)
companyname = re.search(sucker4,content3).group(1)
league = re.search(sucker5,content3).group(1)
zhudui = re.search(sucker6,content3).group(1)
kedui = re.search(sucker6,content3).group(2)
collection = db[date + '_'+ urlnum]
soup = BeautifulSoup(content3,"html5lib")
table = soup.table
tr = soup.find_all('tr')
del tr[0],tr[0],tr[1]
s1 = list()
for x in range(0,len(tr)):
    s1.append(str(tr[x]))


sucker7 = '(>)(.*?)(<)'
s2 = list()#s2为存储时间和赔率的列表
for u in range(0,len(s1)):
    uu = re.findall(sucker7,s1[u])
    uuu = list()
    for w in range(0,len(uu)):
        uuu.append(uu[w][1])
    while '' in uuu:
        uuu.remove('')#去除列表中的空元素
    for i in range(0,len(uuu)):
        if uuu[i][-1] == '↑':#去除列表中的箭头们
            uuu[i] = uuu[i][:-1]
        elif uuu[i][-1] == '↓':
            uuu[i] = uuu[i][:-1]
    for i in range(2,len(uuu)):
        uuu[i] = float(uuu[i])
    s2.append(uuu)


tzinfo = pytz.timezone('Etc/GMT-8')#先定义时区信息,这里代表北京时间
for i in range(0,len(s2)):#把s2中的时间转换成UTC时间
    s2[i][0] = datetime.strptime(s2[i][0][:16],'%Y/%m/%d %H:%M')#先转成datetime实例（北京时间）
    s2[i][0] = s2[i][0].replace(tzinfo = tzinfo)#讲时间都标上北京时间
    s2[i][0] = s2[i][0].astimezone(timezone(timedelta(hours=0)))#转换成utc时间


for i in range(0,len(s2)):#把概率转化成百分比
    s2[i][5] = round(s2[i][5]*0.01,4)#还必须得四舍五入，要不然不是两位小数
    s2[i][6] = round(s2[i][6]*0.01,4)
    s2[i][7] = round(s2[i][7]*0.01,4)


for i in range(0,len(s2)):#把剩余时间转化成分钟数
    match = re.match('赛前(.*?)小时(.*?)分',s2[i][1])
    s2[i][1] = int(match.group(1))*60 + int(match.group(2))#转化成据比赛开始前的剩余分钟数


for i in range(0,len(s2)):#每一次变盘就插入一个记录
    record = {}
    record['league'] = league
    record['cid'] = cid
    record['zhudui'] = zhudui
    record['kedui'] = kedui
    record['companyname'] = companyname
    record['timestamp'] = s2[i][0]
    record['resttime'] = s2[i][1]
    record['peilv'] = [s2[i][2],s2[i][3],s2[i][4]]
    record['gailv'] = [s2[i][5],s2[i][6],s2[i][7]]
    record['kailizhishu'] = [s2[i][8],s2[i][9],s2[i][10]]
    record['fanhuanlv'] = s2[i][11]
